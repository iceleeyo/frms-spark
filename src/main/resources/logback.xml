<configuration>
	<!-- 输出到控制台 -->
	<appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
		<encoder>
			<!-- 输出格式 -->
			<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
		</encoder>
	</appender>

	<!-- error级别单独记录 -->
	<appender name="errorAppender" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<file>logs/spark-error-today.log</file>
		<!-- 以day为单位自动回滚 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<!-- 按天回滚 daily -->
			<fileNamePattern>logs/portal-error/spark-error-%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
			<!-- 日志最大的历史30天 -->
            <maxHistory>30</maxHistory>
            <!-- 日志文件最大的大小 -->
			<timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
				<maxFileSize>100MB</maxFileSize>
			</timeBasedFileNamingAndTriggeringPolicy>
		</rollingPolicy>
		<encoder>
			<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-4relative [%thread] %-5level%logger{35} - %msg%n</pattern>
		</encoder>
		<!-- error级别过滤器 -->
		<filter class="ch.qos.logback.classic.filter.LevelFilter">
			<level>ERROR</level>
			<onMatch>ACCEPT</onMatch>
			<onMismatch>DENY</onMismatch>
		</filter>
	</appender>

	<!-- warn级别单独记录 -->
	<appender name="warnAppender" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<file>logs/spark-warn-today.log</file>
		<!-- 以day为单位自动回滚 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<!-- 按天回滚 daily -->
			<fileNamePattern>logs/spark-warn/portal-warn-%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
			<!-- 日志最大的历史30天 -->
			<maxHistory>30</maxHistory>
			<!-- 日志文件最大的大小 -->
			<timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
				<maxFileSize>100MB</maxFileSize>
			</timeBasedFileNamingAndTriggeringPolicy>
		</rollingPolicy>
		<encoder>
			<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-4relative [%thread] %-5level%logger{35} - %msg%n</pattern>
		</encoder>
		<!-- warn级别过滤器 -->
		<filter class="ch.qos.logback.classic.filter.LevelFilter">
			<level>WARN</level>
			<onMatch>ACCEPT</onMatch>
			<onMismatch>DENY</onMismatch>
		</filter>
	</appender>

	<!-- info级别单独记录 -->
	<appender name="infoAppender" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<file>logs/spark-info-today.log</file>
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<fileNamePattern>logs/spark-info/portal-info-%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
			<!-- 日志最大的历史30天 -->
            <maxHistory>30</maxHistory>
			<!-- 日志文件最大的大小 -->
			<timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
				<maxFileSize>100MB</maxFileSize>
			</timeBasedFileNamingAndTriggeringPolicy>
		</rollingPolicy>
		<encoder>
			<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-4relative [%thread] %-5level%logger{35} - %msg%n</pattern>
		</encoder>
		<!-- info级别过滤器 -->
		<filter class="ch.qos.logback.classic.filter.LevelFilter">
			<level>INFO</level>
			<onMatch>ACCEPT</onMatch>
			<onMismatch>DENY</onMismatch>
		</filter>
	</appender>
	
	<!-- 根，所有logger的祖先 -->
	<root level="INFO">
		<appender-ref ref="STDOUT" />
		<appender-ref ref="errorAppender" />
		<appender-ref ref="warnAppender" />
		<appender-ref ref="infoAppender" />
	</root>
</configuration>